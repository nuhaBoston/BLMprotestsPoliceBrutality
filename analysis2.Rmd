---
title: "R Notebook"
output:
  pdf_document: default
  PDF: default
---

#Importing all necessary libraries for analysis

```{r include=F}
library(tidyverse)
library(car)
library(readxl)
library(GGally)
library(alr4)
#install.packages("AER")
library(AER)
```

#Imported our data to clean up into multiple data frames 

```{r}
alldat<-read_excel("Crime_Rate_2010_2020.xlsx")
rawdat<-read_excel("Crime_Rate_2010_2020.xlsx",sheet=2)
alldat1 <- read.csv("alldat.csv")

```

```{r eval=FALSE, include=FALSE}
alldat$HFR <- hrfstats$HFR
#alldat$kills_norm<-alldat$kills/alldat$
```

```{r eval=FALSE, include=FALSE}
write.csv(alldat, "alldat.csv")
```


```{r}
#colnames(alldat)
```
## Exploratory Analysis of potential regressors,i.e. Number of Kills, Average Median Income, Household Firehold Rate, Average Crime Rate, Number of Protests, Population Density, Percent of Population that has a bachelor's degree, Policing Per Capita Expenditure, Percent of Population that is White/Asian

```{r}
scatterplotMatrix(~kills+`AMI`+ HFR +
                  `Average.Crime.Rate`+`Number.of.Protests`+`PopulationDensity`+
                  `percentbach`+`Policing.Per.Capita.Spend`+`PctWhiteAsian`,
                  regLine=F,smooth=F,data=alldat1, col="#69b3a2", main = "Scatterplot Matrix of All Possible Regressors")
```
We noticed that DC has quite unusual numbers for our regressors which may because it is an urban area that has very high population density compared to states that have very high areas. We decided to do analysis of our data without DC. Similarly CA has the highest population and the highest number 

Without DC or CA
```{r eval=FALSE, include=FALSE}

noDC_CA<-alldat %>% filter(!`Fips Code` %in% c(11,6))  
scatterplotMatrix(~kills+`AMI`+ alldat1$HFR +
                  `Average Crime Rate`+`Number of Protests`+`PopulationDensity`+
                  `percentbach`+`Policing Per Capita Spend`+`PctWhiteAsian`,
                  regLine=F,smooth=F,data=noDC_CA,main="No DC or CA")
```
```{r eval=FALSE, include=FALSE}
#noCA_TX<-alldat %>% filter(!`Fips Code` %in% c(6,48))  
scatterplotMatrix(~log(kills)+`AMI`+ HFR +
                  `Average Crime Rate`+log(`Number of Protests`)+log(`PopulationDensity`)+
                  `percentbach`+`Policing Per Capita Spend`+`PctWhiteAsian`,
                  regLine=F,smooth=F,data=alldat,main="log T of Kills+Protests+Density")
```
Our scatterplot matrix revealed that certain regressors needed to be transformed. We used log transformations because it is monotonic and spreads data points that are compressed at small values and pulls in data points that are spread out at high values. 

We did: number of kills, number of protests, population density

We also created a new variable for rate of kills instead of the raw number.

```{r eval=FALSE, include=FALSE}
alldat$lkills<-log(alldat$kills)
alldat$lprotests<-log(alldat$`Number of Protests`)
alldat$ldensity<-log(alldat$PopulationDensity)
alldat$killsnorm<-(alldat$kills/alldat$PopulationTotal)*1000000
```

We created a joint correlation table of all variables to see if there are any that are highly linearly correlated and might consider leaving them from our model in order not to skew it. 

```{r}
ggcorr(data=alldat,label=F, ma)

```
Instead of a linear regression, we did a poisson model because we are using count data. When dealing with count data, larger or smaller counts may be observed based on the size of the observational unit; we included an offset to counteract this.

We created a base model with our main predictor of interest, i.e. Number of BLM protests 
```{r}
model.2 <- glm(kills~`Number of Protests`,offset(log(PopulationTotal)),
               family = poisson(link = "log"), data = alldat)

summary(model.2)
```
We calculated the chi square statistic to test the deviance of our base model. 

```{r}
pchisq(7189.4,df=49)
```


```{r}
model.2 <- glm(kills~lprotests,
                data = alldat)
summary(model.2)
```
We did both stepwise regression to help with variable selection. 


## Backwards selection 

```{r}
subset <- alldat %>% select(-`Fips Code`, -State)
m1 <- glm(kills ~ `Average Crime Rate`+lprotests+`Policing Per Capita Spend` +
            percentbach+AMI+`Political Affiliation(Binary)`+PctWhiteAsian+ldensity+offset(log(PopulationTotal)), 
          data=alldat,family='poisson')


step(m1,scope=~1, direction="backward")

```
## Forward selection

```{r}
m2<-glm(kills~1,data=subset)
step(m2,scope= ~ `Average Crime Rate`+log(`Number of Protests`)+`Policing Per Capita Spend`+ HFR+
            percentbach+AMI+`Political Affiliation(Binary)`+PctWhiteAsian+log(PopulationDensity)+offset(log(PopulationTotal)), direction="forward")


```
```{r}
back.model<-glm(kills~lprotests+percentbach+ldensity+PctWhiteAsian+offset(log(PopulationTotal)),
                  data=alldat,family="poisson")
```

```{r}
summary(back.model)
```

Both models were very similar however one included the variable for percent of population with bachelors. We analyzed the model to see how significant this variable was. 
```{r}
forw.model<-glm(kills~lprotests+ldensity+PctWhiteAsian+offset(log(PopulationTotal)),
                  data=alldat,family="poisson")

summary(forw.model)
```
```{r}
Anova(back.model)
```
## LR test for including percentbach or not

```{r}
1-pchisq(193.66-172.76,df=1)
```
It was significant so we included the variable in the model. We then explored interaction terms. Our first try was with log(protests) and percentbach. 

```{r}
int.model1<-glm(kills~lprotests+percentbach+ldensity+PctWhiteAsian+lprotests:percentbach
                +offset(log(PopulationTotal)),
                  data=alldat,family="poisson")
summary(int.model1)
```

```{r}
Anova(int.model1)
```

We were curious to see how Average Crime Rate would impact our model, based on literature we had read for context. 
```{r}
alldat$ACR<-alldat$`Average Crime Rate`

crime.mod<-glm(kills~lprotests+percentbach+ldensity+PctWhiteAsian+ACR+lprotests:percentbach
                +offset(log(PopulationTotal)),
                  data=alldat,family="poisson")
summary(crime.mod)
```

```{r}
plot(effect("ACR",crime.mod,))
test<-summary(effect("ACR",crime.mod))

```
## Residuals
```{r}
plot(residuals(int.model1,"pearson"))

```
We tested to see how large the overdispersion would be. Naturally overdispersion happens in models in which the two parameters, i.e. 
## Overdispersion
```{r}
AER::dispersiontest(int.model1)
```

```{r}
alldat1$PPC = alldat1$`Policing.Per.Capita.Spend`
alldat$PoliticalAffiliation = alldat$`Political.Affiliation(Binary)`

m1.hfr <- glm(kills ~ lprotests+ PPC + HFR +
            percentbach+AMI+ PoliticalAffiliation+PctWhiteAsian+ldensity+offset(log(PopulationTotal)), 
          data=alldat1,family='poisson')
plot(effect("HFR", m1.hfr), main = "Effects of Household Firearm Rate")
```


```{r}
Anova(m1.hfr)
```
```{r}
#Backward Selection
step(m1.hfr, scope=~1, direction="backward")

```

```{r}
m1.hfrbackward <- glm(kills ~ lprotests + HFR + percentbach + AMI + PctWhiteAsian + 
    ldensity + offset(log(PopulationTotal)), family = "poisson", 
    data = alldat)

m1.hfrinteraction <- glm(kills ~ lprotests+ PPC + HFR +
            percentbach+AMI+ PoliticalAffiliation+PctWhiteAsian+ldensity+ ldensity:HFR + offset(log(PopulationTotal)), 
          data=alldat,family='poisson')
summary(m1.hfr)
summary(m1.hfrbackward)
summary(m1.hfrinteraction)
```

```{r}
step(m1.hfrinteraction, scope=~1, direction="backward")
```

```{r}
mainmodel <- glm(kills ~ lprotests + HFR + percentbach + AMI + PctWhiteAsian + 
    ldensity + HFR:ldensity + offset(log(PopulationTotal)), family = "poisson", 
    data = alldat1)


plot(residuals(mainmodel, "pearson"))
```
```{r}
library(pander)
Anova(mainmodel)  %>% pander()


```


```{r}
plot(effect("HFR", mainmodel), main = "Effects of Household Firearm Rate")
plot(effect("lprotests", mainmodel), main = "Effects of LProtests")
```

```{r}
AER::dispersiontest(mainmodel)
#install.packages("PseudoR2")
#library(DescTools)
#library(PseudoR2)
#PseudoR2(mainmodel, which = "McKelveyZavoina")
```




